2025-03-11 18:41:42,469 - ERROR - Error on loading the LLM(LLAMA or VICUNA.
Traceback (most recent call last):
  File "/home/leonardosouza/projects/certifiedGPT/graphs/models/minigpt4/models/base_model.py", line 190, in init_llm
    llama_tokenizer = LlamaTokenizer.from_pretrained(llama_model_path, use_fast=False)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 1825, in from_pretrained
    return cls._from_pretrained(
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 1988, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/transformers/models/llama/tokenization_llama.py", line 96, in __init__
    self.sp_model.Load(vocab_file)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
RuntimeError: Internal: unk is not defined.
2025-03-13 22:40:56,117 - ERROR - Error on loading the LLM(LLAMA or VICUNA.
Traceback (most recent call last):
  File "/home/leonardosouza/projects/certifiedGPT/graphs/models/minigpt4/models/base_model.py", line 190, in init_llm
    llama_tokenizer = LlamaTokenizer.from_pretrained(llama_model_path, use_fast=False)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 1825, in from_pretrained
    return cls._from_pretrained(
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 1988, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/transformers/models/llama/tokenization_llama.py", line 96, in __init__
    self.sp_model.Load(vocab_file)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/sentencepiece/__init__.py", line 961, in Load
    return self.LoadFromFile(model_file)
  File "/home/leonardosouza/.conda/envs/certifiedgpt/lib/python3.9/site-packages/sentencepiece/__init__.py", line 316, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
RuntimeError: Internal: could not parse ModelProto from ""
